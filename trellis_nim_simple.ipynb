{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üé® Trellis NIM - Simple Deployment & Inference\n",
        "\n",
        "A streamlined notebook for deploying NVIDIA Trellis NIM and generating 3D models from text prompts using command line interface.\n",
        "\n",
        "## What This Notebook Does:\n",
        "1. **üîß GPU Check** - Verify L40s GPU availability  \n",
        "2. **üöÄ Deploy NIM** - Run the Trellis NIM container\n",
        "3. **‚ö° Generate Models** - Command line 3D generation from text prompts\n",
        "\n",
        "## Key Features:\n",
        "- ‚úÖ **Simple setup** - Just run the cells in order\n",
        "- ‚úÖ **Command line generation** - Direct API calls to NIM service\n",
        "- ‚úÖ **GLB output** - High-quality 3D models ready for Blender, Unity, etc.\n",
        "- ‚úÖ **Container management** - Easy start, stop, and status checking\n",
        "\n",
        "**üöÄ From setup to 3D models in minutes!**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Check GPU Availability\n",
        "\n",
        "Verify that we have access to an L40s GPU:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Deploy Trellis NIM Container\n",
        "\n",
        "**‚ö†Ô∏è IMPORTANT**: Replace `<PASTE_API_KEY_HERE>` with your actual NGC API key from https://ngc.nvidia.com/setup/api-key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set your NGC API key here\n",
        "import os\n",
        "os.environ['NGC_API_KEY'] = '<PASTE_API_KEY_HERE>'  # Replace with your actual API key\n",
        "\n",
        "# Verify the API key is set\n",
        "if os.environ['NGC_API_KEY'] == '<PASTE_API_KEY_HERE>':\n",
        "    print('‚ùå Please replace <PASTE_API_KEY_HERE> with your actual NGC API key!')\n",
        "else:\n",
        "    print('‚úÖ NGC API key is set')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Docker login to NGC registry\n",
        "!echo \"$NGC_API_KEY\" | docker login nvcr.io --username '$oauthtoken' --password-stdin\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create cache directory\n",
        "!mkdir -p ~/.cache/nim\n",
        "!chmod 777 ~/.cache/nim\n",
        "!echo \"Cache directory created at: ~/.cache/nim\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start Trellis NIM container (this will run in the background)\n",
        "# Note: This may take several minutes to download and start the first time\n",
        "\n",
        "!docker run -d --name=nim-server \\\n",
        "  --runtime=nvidia --gpus='\"device=0\"' \\\n",
        "  -e NGC_API_KEY=$NGC_API_KEY \\\n",
        "  -p 8000:8000 \\\n",
        "  -v ~/.cache/nim:/opt/nim/.cache/ \\\n",
        "  nvcr.io/nim/microsoft/trellis:latest\n",
        "\n",
        "print('üöÄ Trellis NIM container started!')\n",
        "print('‚è≥ Please wait 2-5 minutes for the container to fully initialize...')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check container status\n",
        "!docker ps | grep nim-server\n",
        "!echo \"\\nüìä Container logs (last 10 lines):\"\n",
        "!docker logs nim-server --tail 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üåê Launch Open Web UI - Interactive 3D Generation Interface\n",
        "# \n",
        "# This launches a beautiful web interface to generate 3D models interactively!\n",
        "# The UI connects to your deployed Trellis NIM following the NVIDIA Build platform pattern.\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "import webbrowser\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"üöÄ Starting Open Web UI for Trellis 3D Generation...\")\n",
        "print(\"üîó Following NVIDIA Build pattern: https://build.nvidia.com/microsoft/trellis\")\n",
        "\n",
        "# Navigate to the web UI directory\n",
        "web_ui_path = Path(\"./prompt-to-trellis\")\n",
        "if not web_ui_path.exists():\n",
        "    print(\"‚ùå Web UI directory not found at ./prompt-to-trellis\")\n",
        "    print(\"üí° Make sure you're running this from the trellis-image-vision root directory\")\n",
        "else:\n",
        "    print(\"‚úÖ Found Web UI directory\")\n",
        "    \n",
        "    # Check if NIM is running\n",
        "    nim_check = subprocess.run(['docker', 'ps'], capture_output=True, text=True)\n",
        "    if 'nim-server' in nim_check.stdout:\n",
        "        print(\"‚úÖ Trellis NIM is running\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  Warning: Trellis NIM container not detected. Make sure it's running first!\")\n",
        "        print(\"üí° Run the deployment cells above to start the NIM container\")\n",
        "    \n",
        "    # Change to web UI directory and install dependencies if needed\n",
        "    os.chdir(web_ui_path)\n",
        "    \n",
        "    # Check if node_modules exists\n",
        "    if not Path(\"node_modules\").exists():\n",
        "        print(\"üì¶ Installing dependencies...\")\n",
        "        subprocess.run(['npm', 'install'], check=True)\n",
        "    \n",
        "    print(\"üåê Starting development server...\")\n",
        "    print(\"üìç Web UI will be available at: http://localhost:5173\")\n",
        "    print(\"üéØ This provides the same interface as https://build.nvidia.com/microsoft/trellis\")\n",
        "    print(\"‚ú® You can now prompt for 3D models in your browser!\")\n",
        "    \n",
        "    # Start the development server in the background\n",
        "    server_process = subprocess.Popen(['npm', 'run', 'dev'], \n",
        "                                    stdout=subprocess.PIPE, \n",
        "                                    stderr=subprocess.PIPE)\n",
        "    \n",
        "    # Wait a moment for server to start\n",
        "    time.sleep(3)\n",
        "    \n",
        "    # Open browser\n",
        "    webbrowser.open('http://localhost:5173')\n",
        "    \n",
        "    print(\"\\nüéâ Open Web UI is now running!\")\n",
        "    print(\"üìñ Usage:\")\n",
        "    print(\"  ‚Ä¢ Enter your text prompt in the interface\")\n",
        "    print(\"  ‚Ä¢ Click 'Generate 3D Model' to create your model\")\n",
        "    print(\"  ‚Ä¢ Download the .glb file when generation completes\")\n",
        "    print(\"\\n‚ö†Ô∏è  To stop the server: Press Ctrl+C in the terminal or restart this kernel\")\n",
        "    \n",
        "    # Keep the process running - in Jupyter this will show output as it comes\n",
        "    try:\n",
        "        server_process.wait()\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nüõë Stopping Web UI server...\")\n",
        "        server_process.terminate()\n",
        "        print(\"‚úÖ Web UI server stopped\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Generate 3D Models (Command Line Method)\n",
        "\n",
        "**üåê RECOMMENDED: Use the Web Interface (Cell 14) for the best experience!**\n",
        "\n",
        "Alternatively, you can generate models via command line by changing the prompt below and running the cell:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#CHANGE THIS PROMPT TO GENERATE DIFFERENT 3D MODELS. BRANDS OR SPECIFIC PRODUCTS WILL FAIL THE GENERATION. \n",
        "PROMPT = \"A simple coffee shop interior\"\n",
        "\n",
        "#Change output filename\n",
        "OUTPUT_FILE = \"result.glb\"\n",
        "\n",
        "# Optional: Change the seed for different variations (0 = random)\n",
        "SEED = 0\n",
        "\n",
        "# First, let's test if the NIM container is responding\n",
        "print(\"üîç Testing NIM container connectivity...\")\n",
        "health_check = !curl -s http://localhost:8000/health || curl -s http://localhost:8000/ || echo \"CONNECTION_FAILED\"\n",
        "\n",
        "if \"CONNECTION_FAILED\" in ' '.join(health_check):\n",
        "    print(\"‚ùå Cannot connect to NIM container at http://localhost:8000\")\n",
        "    print(\"üí° Make sure the container is running with: docker ps | grep nim-server\")\n",
        "    print(\"üí° Check container logs with: docker logs nim-server\")\n",
        "else:\n",
        "    print(\"‚úÖ NIM container is responding\")\n",
        "\n",
        "print(\"\\nüì° Sending generation request to Trellis NIM...\")\n",
        "\n",
        "# Use the exact curl command format from your original request\n",
        "import subprocess\n",
        "import json\n",
        "import base64\n",
        "\n",
        "# Create the JSON payload\n",
        "json_payload = json.dumps({\n",
        "    \"prompt\": PROMPT,\n",
        "    \"seed\": SEED\n",
        "})\n",
        "\n",
        "# Execute curl command exactly as specified\n",
        "curl_cmd = [\n",
        "    'curl', '-X', 'POST', 'http://localhost:8000/v1/infer',\n",
        "    '-H', 'Accept: application/json',\n",
        "    '-H', 'Content-Type: application/json',\n",
        "    '-d', json_payload,\n",
        "    '--silent'\n",
        "]\n",
        "\n",
        "print(f\"üéØ Generating: '{PROMPT}'\")\n",
        "print(\"‚è≥ This may take 1-3 minutes...\")\n",
        "\n",
        "try:\n",
        "    # Run the curl command\n",
        "    result = subprocess.run(curl_cmd, capture_output=True, text=True, timeout=300)\n",
        "    \n",
        "    if result.returncode != 0:\n",
        "        print(f\"‚ùå Curl command failed with return code: {result.returncode}\")\n",
        "        print(f\"Error: {result.stderr}\")\n",
        "        print(f\"Command: {' '.join(curl_cmd)}\")\n",
        "    else:\n",
        "        response_text = result.stdout.strip()\n",
        "        print(f\"üì® Raw response length: {len(response_text)} characters\")\n",
        "        print(f\"üì® Response preview: {response_text[:300]}...\")\n",
        "        \n",
        "        if not response_text:\n",
        "            print(\"‚ùå Empty response from server\")\n",
        "        elif response_text.startswith('<!DOCTYPE') or '<html' in response_text:\n",
        "            print(\"‚ùå Received HTML response instead of JSON - check if container is fully started\")\n",
        "        else:\n",
        "            try:\n",
        "                # Parse JSON response\n",
        "                response_data = json.loads(response_text)\n",
        "                print(\"‚úÖ Valid JSON response received\")\n",
        "                \n",
        "                # Check for artifacts in response\n",
        "                if 'artifacts' in response_data and len(response_data['artifacts']) > 0:\n",
        "                    artifact = response_data['artifacts'][0]\n",
        "                    if 'base64' in artifact:\n",
        "                        base64_data = artifact['base64']\n",
        "                        \n",
        "                        # Decode and save the GLB file\n",
        "                        glb_data = base64.b64decode(base64_data)\n",
        "                        \n",
        "                        with open(OUTPUT_FILE, 'wb') as f:\n",
        "                            f.write(glb_data)\n",
        "                        \n",
        "                        print(f\"‚úÖ SUCCESS! 3D model saved as: {OUTPUT_FILE}\")\n",
        "                        print(f\"üìä File size: {len(glb_data) / 1024:.2f} KB\")\n",
        "                        print(f\"üéØ You can now open {OUTPUT_FILE} in any 3D viewer or Blender!\")\n",
        "                    else:\n",
        "                        print(\"‚ùå No base64 data in artifact\")\n",
        "                        print(f\"Artifact keys: {list(artifact.keys())}\")\n",
        "                else:\n",
        "                    print(\"‚ùå No artifacts found in response\")\n",
        "                    print(f\"Response keys: {list(response_data.keys())}\")\n",
        "                    if 'error' in response_data:\n",
        "                        print(f\"Error from server: {response_data['error']}\")\n",
        "                        \n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"‚ùå Failed to parse JSON response: {e}\")\n",
        "                print(f\"Raw response: {response_text}\")\n",
        "\n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"‚ùå Request timed out (>5 minutes)\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Unexpected error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ That's it!\n",
        "\n",
        "### To generate more 3D models:\n",
        "1. Go back to the cell above with `PROMPT = \"...\"` and `OUTPUT_FILE = \"... .glb\"`\n",
        "2. Change the prompt to whatever you want\n",
        "3. Run both cells again\n",
        "\n",
        "### Example prompts to try:\n",
        "- `\"A modern chair\"`\n",
        "- `\"A futuristic car\"`\n",
        "- `\"A wooden table\"`\n",
        "- `\"A cozy bedroom\"`\n",
        "- `\"A space station interior\"`\n",
        "\n",
        "### Useful commands:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if NIM container is running\n",
        "!docker ps | grep nim-server\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Management Commands\n",
        "\n",
        "Use these cells to manage your NIM container:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check NIM container status\n",
        "import subprocess\n",
        "\n",
        "print(\"üîç NIM STATUS CHECK\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Check NIM container\n",
        "print(\"üì¶ NIM Container Status:\")\n",
        "nim_check = subprocess.run(['docker', 'ps'], capture_output=True, text=True)\n",
        "if 'nim-server' in nim_check.stdout:\n",
        "    print(\"‚úÖ NIM container is running\")\n",
        "    !docker ps | grep nim-server\n",
        "else:\n",
        "    print(\"‚ùå NIM container is not running\")\n",
        "\n",
        "# Check NIM API health  \n",
        "print(\"\\nüîó NIM API Health:\")\n",
        "import requests\n",
        "try:\n",
        "    response = requests.get(\"http://localhost:8000/health\", timeout=5)\n",
        "    if response.status_code == 200:\n",
        "        print(\"‚úÖ NIM API is responding\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è NIM API returned status: {response.status_code}\")\n",
        "except:\n",
        "    try:\n",
        "        response = requests.get(\"http://localhost:8000/\", timeout=5)\n",
        "        print(\"‚úÖ NIM service is responding\")\n",
        "    except:\n",
        "        print(\"‚ùå NIM API is not accessible\")\n",
        "\n",
        "print(\"\\nüìä Port 8000 Status:\")\n",
        "!netstat -an | grep \":8000\" | grep LISTEN || echo \"No service found on port 8000\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View recent container logs\n",
        "!docker logs nim-server --tail 20\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stop the NIM container (when you're done)\n",
        "!docker stop nim-server\n",
        "!docker rm nim-server\n",
        "print(\"üõë Trellis NIM container stopped and removed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Generation Complete!\n",
        "\n",
        "### To generate more 3D models:\n",
        "1. Go back to the cell above and change `PROMPT = \"...\"`\n",
        "2. Optionally change `OUTPUT_FILE = \"...\"` to save with a different name\n",
        "3. Run the cell again\n",
        "\n",
        "### Example prompts to try:\n",
        "- `\"A modern chair\"`\n",
        "- `\"A futuristic car\"`\n",
        "- `\"A wooden table\"`\n",
        "- `\"A cozy bedroom\"`\n",
        "- `\"A space station interior\"`\n",
        "- `\"A medieval castle tower\"`\n",
        "- `\"A vintage coffee shop interior\"`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View recent container logs\n",
        "!docker logs nim-server --tail 20\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stop the NIM container (when you're done)\n",
        "!docker stop nim-server\n",
        "!docker rm nim-server\n",
        "print(\"üõë Trellis NIM container stopped and removed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List generated GLB files\n",
        "!ls -la *.glb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Complete!\n",
        "\n",
        "### **üéâ Your Trellis NIM setup is now complete!**\n",
        "\n",
        "**What you have:**\n",
        "- ‚úÖ **NVIDIA Trellis NIM** deployed and running\n",
        "- ‚úÖ **Command-line generation** - Simple, reliable 3D model creation\n",
        "- ‚úÖ **GLB output files** - Ready for Blender, Unity, or any 3D software\n",
        "- ‚úÖ **Container management** - Easy start, stop, and monitoring\n",
        "\n",
        "### **üöÄ Workflow:**\n",
        "1. **Deploy NIM**: Run cells 2-8 (one-time setup)\n",
        "2. **Generate models**: Use cell 10, change the prompt and run\n",
        "3. **Manage container**: Use cells 12-15 for monitoring and cleanup\n",
        "\n",
        "### **üõ†Ô∏è Troubleshooting:**\n",
        "- **Container not responding** ‚Üí Check `docker logs nim-server`\n",
        "- **Generation fails** ‚Üí Verify container is running with `docker ps | grep nim-server`\n",
        "- **Out of memory** ‚Üí Restart container with `docker restart nim-server`\n",
        "\n",
        "### **üìÅ Files:**\n",
        "- **Generated Models**: `.glb` files in the current directory\n",
        "- **NIM Service**: Running on http://localhost:8000\n",
        "\n",
        "**üé® Ready to create amazing 3D models from text prompts!**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
